\subsection{Measure of non-gaussianity}

We are first going to explain the formula \eqref{eq:gen}.
Assume that we have a random vector $\X$ with density $f_\X$. A most common
measure of non-gaussianity is given by the Lullback-Leibler divergence with respect to 
the gaussian measure.
Recall that for a random vector $\X$ finite covariance matrix, its non-Gaussianness is given by
$$
\begin{array}{l}
D(\X)=D(f_\X)=D(f_\X \| \nor(\mean_\X,\cov_\X))\\[1ex]
=\frac{1}{2}\log \det(2\pi e \cov_\X)-h(f_\X),
\end{array}
$$
where $h$ denotes the entropy and $D(f\|g)$ Kullback-Leibler divergence.
It is well-known \cite{cover2012elements} that $D(\X)=0$ iff $\X$ is Gaussian.
Clearly, the above measure is affine invariant.

In practice we have only a finite sample $X$ from $\X$ (that is our data-set). In this case, given a 
family $\F$ of densites on $\R^D$, we can first obtain estimation of the density
by MLE in the class $\F$, and only later compute the measure of nongaussianity. We use the following
notation: given a set $X$, by $\de{X,\F}$ we denote the MLE estimation of the original density $X$ comes from. Thus in this case 
$$
D(X,\F)=\frac{1}{2}\log \det(2\pi e \cov_X)-h(X,\F)
$$ 
is the estimation of the nongaussianity, where $h(X,\F)$ is the estimation of the entropy of $X$
with the use of best estimation from class $\F$: 
$$
h(X,\F)=\frac{1}{\card X}\sum_x -\ln (\de{X,\F}(x)).
$$
Observe that to maximize the above, since the first part is constant, we can minimize
$h(\de{X,\F})$, which is equivalent to maximization of the MLE.

To describe the ability of change of variables, we use the notation based on the push-forward of measures
%
%.Natural method of defining by push-forward
%for more information see \url{https://en.wikipedia.org/wiki/Pushforward_measure},
%\url{http://www.mat.univie.ac.at/~gerald/ftp/book-fa/index.html} (page 256) and
\cite{bogachev2007measure}. Assume that we have a measure on $\R^D$ with density $f$ coming from the random variable $\X$. Then for a linear invertible function $V$, $V\X$ has the density 
$$
V_*f(x)=\frac{1}{|V|} f(V^{-1}y) \text{ for } x \in \R^D.
$$
%Formally it is a push-forward of the measure $\mu$, we denote it by $V_*\mu$, we use
%analogical notation to denote $V_* f$. 
Consider now the case when $f(x_1,\ldots,x_n)=f_1(x_1)\cdot \ldots f_n(x_n)$, that is $f$
is a product measure with respect to base coordinates. In other words, to compute $f(x)$, we can
write
$$
x=x_1 e_1+\ldots +x_n e_n
$$
and compute $f(x)=f_1(x_1) \cdot \ldots \cdot f_n(x_n)$. Now if we want to consider the base given by $V=[\v_1,\ldots,\v_n]$ and the analogue of the above,
we take $x=x_1 \v_1 +\ldots +x_n \v_n$ and 
$$
\frac{1}{\det V} f(x_1) \cdot \ldots \cdot  f(x_n)=V_*f(x).
$$
This is exactly the above.


In our case we will focus our attention on the task of finding $d$ components which are as non-gaussian as possible. For the simplest case, assume that we first consider the first $d$ coordinates, 
and that we want to measure how $X$ is far from being gaussian on the first coordinates. To do so we first need a family $\F_d$ of densities on $\R^d$, which is larger then gaussians. Now we consider
$$
D(X,\F_d \otimes \nor_{D-d}),
$$
where the tensor product of densities is defined by $(f \otimes g)(x,y)=f(x) \cdot g(y)$.

However, in general working with high-dimensional densities, is nontrivial, and therefore for simplicity we fix a family of one dimensional densities that is larger then gaussians $\F$, and take tensor product of $d$-elements of $\F$, that is $\F^{\otimes d}$ (in our case it would be the family of split-gaussians). Thus we search for
$$
\begin{array}{l}
\argmax \limits_V D(X;V_*(\F^{\otimes d} \otimes \nor_{D-d})) \\[1ex]
=\argmin \limits_V h(\de{X,V_*(\F^{\otimes d} \otimes \nor_{D-d}}).
\end{array}
$$
Thus if we reduce to split gaussians of first $d$-dimensions, put $W=V^{-1}$, we get the formulation we described in the introduction.

\medskip

\noindent PROBLEM. {\em Let $X \subset \R^D$ be a data set, and $d \leq D$ be given.
Find a matrix $W=[\w_1,\ldots,\w_D]$, densities $f_1,\ldots,f_d \in \SN$, $f_{d+1},\ldots,f_D \in \nor$, such that 
the likelihood of drawing $X$ from the density
$$
x \to \det(W) \cdot f_1(\w_1^Tx) \cdot \ldots \cdot f_D(\w_D^T x)
$$
is maximized.}

\medskip

