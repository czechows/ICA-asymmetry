%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Experiments}
\label{experiments}


\begin{table*}[t]
\caption{Tucker's congruence coefficients for reconstruction of two images.}
\label{tab:congru_img_1}
\vskip 0.15in
\begin{center}
\begin{small}
\begin{sc}
\resizebox{\textwidth}{!}{
\begin{tabular}{ c c c c c c c c c  c  c  c  c }
\hline
%\abovespace\belowspace
 & \ICA  & FastICA & FastICA & FastICA & Infomax & Infomax & Infomax & JADE & PearsonICA & ProDenICA & FixNA \\ 
  &  &  logcosh & exp & kurtosis & tanh & tangent & logistic &  & & &  \\
\hline
%\abovespace
4.1.01 & 0.99984  &  0.59585  &  0.59967  &  0.58722  &  0.59596  &  0.58965  &  0.59589  &  0.58333  &  0.46302  &  0.83162  &  0.99948  \\
4.1.02 & 1  &  0.93572  &  0.93315  &  0.94044  &  0.93564  &  0.93925  &  0.93569  &  0.94215  &  0.92294  &  0.98521  &  0.99325  \\ \hline
4.1.06 & 0.9959  &  0.61189  &  0.61636  &  0.59603  &  0.61599  &  0.60059  &  0.69578  &  0.5629  &  0.5971  &  0.99852  &  0.99937  \\
4.1.03 & 0.8676  &  0.79174  &  0.78969  &  0.7982  &  0.78986  &  0.79647  &  0.72715  &  0.80803  &  0.79781  &  0.87541  &  0.99811  \\ \hline
4.2.04 & 0.99955  &  0.60087  &  0.6007  &  0.60071  &  0.60088  &  0.60094  &  0.60087  &  0.59933  &  0.57862  &  0.98594  &  0.88695  \\
5.2.10 & 0.99974  &  0.94413  &  0.9406  &  0.95526  &  0.94426  &  0.94951  &  0.94395  &  0.96464  &  0.98256  &  0.97757  &  0.88972  \\ \hline
4.2.02 & 0.99679  &  0.59655  &  0.59712  &  0.59554  &  0.59658  &  0.59538  &  0.59656  &  0.59434  &  0.59743  &  0.99237  &  0.96088  \\
5.2.08 & 0.99021  &  0.97131  &  0.96951  &  0.97395  &  0.97122  &  0.97433  &  0.97128  &  0.97647  &  0.96843  &  0.98366  &  0.94757  \\ \hline
boat.512 & 0.99732  &  0.58702  &  0.58689  &  0.58784  &  0.58692  &  0.58748  &  0.58623  &  0.5865  &  0.58728  &  0.99835  &  0.93781  \\
5.3.01 & 0.80906  &  0.98201  &  0.98196  &  0.98213  &  0.98197  &  0.98213  &  0.98163  &  0.98177  &  0.98209  &  0.97381  &  0.97218  \\ \hline
elaine.512 & 0.96643  &  0.58926  &  0.58919  &  0.59017  &  0.58922  &  0.58987  &  0.58935  &  0.58929  &  0.58901  &  0.65476  &  0.71303  \\
4.2.03 & 0.99839  &  0.96629  &  0.96628  &  0.96641  &  0.96628  &  0.96638  &  0.96631  &  0.9663  &  0.96624  &  0.99326  &  0.79288  \\ \hline
119082 & 0.99995  &  0.59432  &  0.59502  &  0.59347  &  0.59391  &  0.59374  &  0.59492  &  0.58197  &  0.58604  &  0.99233  &  0.76561  \\
157055 & 0.99804  &  0.94331  &  0.94273  &  0.94397  &  0.94363  &  0.94377  &  0.94281  &  0.94928  &  0.94804  &  0.93969  &  0.73722  \\ \hline
42049 & 0.9999  &  0.63238  &  0.61046  &  0.62306  &  0.63239  &  0.62743  &  0.6324  &  0.61757  &  0.5872  &  0.93106  &  0.88476  \\
220075 & 0.99845  &  0.79121  &  0.70406  &  0.91538  &  0.79133  &  0.90155  &  0.79148  &  0.92798  &  0.96143  &  0.9678  &  0.93793  \\ \hline
43074 & 0.98658  &  0.58577  &  0.58375  &  0.59414  &  0.58555  &  0.59142  &  0.58612  &  0.59278  &  0.55845  &  0.57092  &  0.78144  \\
295087 & 0.99757  &  0.97911  &  0.98011  &  0.97119  &  0.97923  &  0.97465  &  0.97891  &  0.97306  &  0.97978  &  0.99416  &  0.80112  \\ \hline
38092 & 0.95367  &  0.58677  &  0.58678  &  0.58699  &  0.58677  &  0.58692  &  0.58675  &  0.587  &  0.58572  &  0.38511  &  0.76369  \\
167062 & 0.99999  &  0.9916  &  0.9916  &  0.99139  &  0.9916  &  0.99148  &  0.99161  &  0.99137  &  0.99148  &  0.99881  &  0.74187  \\ \hline
\end{tabular}
}
\end{sc}
\end{small}
\end{center}
\vskip -0.1in
\end{table*}




To compare \ICA{} to other state-of-the-art approaches we use 
Tucker's congruence coefficient \cite{lorenzo2006tucker} which values range between $-1$ and $+1$. It can be used to study the similarity of extracted factors across different samples. Generally, a congruence coefficient of $0.9$ indicates a high degree of factor similarity, while a coefficient of $0.95$ or higher indicates that the factors are virtually identical. 

We evaluate our method in the context of 2D and hyperspectral images. 
For comparison we use R package {\tt ica} \cite{ica}, {\tt PearsonICA} \cite{pearsonica}, {\tt ProDenICA} \cite{prodenica}, {\tt tsBSS} \cite{tsBSS}.
The most popular method used in practice is FastICA \cite{hyvarinen1999fast,helwig2013critique} algorithm, which uses negentropy. In this context we can use three different functions to estimate neg-entropy:
logcosh, exp and kurtosis.
We also compare our method with algorithm using Information-Maximization (Infomax) approach \cite{bell1995information}. Similarly to FastICA we consider three possible non-linear functions: hyperbolic tangent, logistic and extended Infomax.
%We also consider algorithm which uses Joint Approximate Diagonalization of Eigenmatrices (JADE) proposed by Cardoso and Souloumiac's \cite{cardoso1993blind,helwig2013critique}.
%
%One of the most popular ICA methods dedicated for skew data is PearsonICA \cite{karvanen2000pearson,karvanen2002blind}, which minimizes mutual information using a Pearson \cite{stuart1968advanced} system-based parametric model. Another model we consider is ProDenICA \cite{bach2002kernel,hastie2009elements}, which is based not on a
%single nonlinear function, but on an entire function space of candidate nonlinearities. In particular, the method works with the functions in a reproducing kernel Hilbert space, and make use of the “kernel trick” to search over this space efficiently. 
%We also compare our method with  FixNA \cite{shi2009blind}, method for blind source separation problem.
%




\subsection{Separation of images}

One of the most popular application of ICA is the separation of images. In our experiments we use four images from the USC-SIPI Image Database of size $256 \times 256$ pixels (4.1.01, 4.1.06, 4.1.02, 4.1.03) and eight of size $512 \times 512$ pixels (4.2.04, 4.2.02, boat.512, elaine.512, 5.2.10, 5.2.08, 5.3.01, 4.2.03). We also use 8 images from the Berkeley Segmentation Dataset of size $482 \times 321$ with indexes (\#119082, \#42049, \#43074, \#38092, \#157055, \#220075, \#295087, \#167062). 

We make random pairs of above images and one component with noise (random sample from Gaussian distribution $\nor(0,1)$) and use them as a source signal combined by the mixing matrix $A = \begin{bmatrix} 1 & 1 & 1  \\ 1 & -1 & -1 \\ -1 & 1 & -1  \end{bmatrix} $. Our goal was to reconstruct two original images by using only the knowledge about mixed ones. The visualization of this process we present in Fig. \ref{fig:image_ICA_int}. The results of this experiment are presented in Tab.~\ref{tab:congru_img_1} where we present Tucker's congruence coefficients which shows that almost in all cases \ICA{} obtains best results. This is illustrated in Figure \ref{fig:image_ICA_int}, where we can see that \ICA {} almost perfectly recovered source signal. 
Although this is not surprising as the experiments were in fact conducted in the setting which favored our approach, as we chose the noise to be gaussian, this shows that \ICA{} works as desired and deals well with removing gaussian
components from the data. 



%\begin{landscape}
\begin{figure*}[t!]
% ensure that we have normalsize text
\normalsize
\begin{center}
%\subfigure[The effect of the \ICA \ method.] {\label{fig:image_1}
%  \includegraphics[width=1.2in]{spec/1a} 
%  \includegraphics[width=1.2in]{spec/2a}
%  \includegraphics[width=1.2in]{spec/3a} 
%  \includegraphics[width=1.2in]{spec/4a}
%} \\
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subfigure[Ground truth layers which contains 4 channels: \#1 Asphalt, \#2 Grass, \#3 Tree and \#4 Roof.] {\label{fig:image_1}
  \includegraphics[width=1.2in]{spec/O_1} 
  \includegraphics[width=1.2in]{spec/O_2}
  \includegraphics[width=1.2in]{spec/O_3} 
  \includegraphics[width=1.2in]{spec/O_4}
} \\
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subfigure[The effect of the \ICA \ method.] {\label{fig:image_1}
  \includegraphics[width=1.2in]{spec/SG_1} 
  \includegraphics[width=1.2in]{spec/SG_2}
  \includegraphics[width=1.2in]{spec/SG_3} 
  \includegraphics[width=1.2in]{spec/SG_4}
} \\
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subfigure[The effect of the FastICA (logcosh) method.] {\label{fig:image_1}
  \includegraphics[width=1.2in]{spec/ICA11_1} 
  \includegraphics[width=1.2in]{spec/ICA11_2}
  \includegraphics[width=1.2in]{spec/ICA11_3} 
  \includegraphics[width=1.2in]{spec/ICA11_4}
} \\
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\subfigure[The effect of the PearsonICA method.] {\label{fig:image_1}
%  \includegraphics[width=1.2in]{spec/ica_41} 
%  \includegraphics[width=1.2in]{spec/ica_42}
%  \includegraphics[width=1.2in]{spec/ica_43} 
%  \includegraphics[width=1.2in]{spec/ica_44}
%} \\
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subfigure[The effect of the  ProDenICA method.] {\label{fig:image_1}
  \includegraphics[width=1.2in]{spec/ICA5_1} 
  \includegraphics[width=1.2in]{spec/ICA5_2}
  \includegraphics[width=1.2in]{spec/ICA5_3} 
  \includegraphics[width=1.2in]{spec/ICA5_4}
} \\
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{center}
\caption{Results of image separation with the uses of various ICA algorithms.}
\label{fig:spec_1}
\end{figure*}


\subsection{Hyperspectral Unmixing}

Independent component analysis has been recently
applied into hyperspectral unmixing 
\cite{wang2015abundance, caiafa2008blind}
as a result of its low
computation time and its ability to perform without prior information.
In this subsection we apply simple example which suggests that our method also can by used for spectral data.

Urban data  \cite{fyzhu2014IJPRSSSNMF,fyzhu2014TIPDgSNMF,fyzhu2014JSTSPRRLbSF} is one of the most widely used hyperspectral data-sets used in the hyperspectral unmixing study. Each image has $307 \times 307$ pixels, each of which corresponds to a $2 \times 2$ m area. In this image, there are 210 wavelengths ranging from 400 nm  to 2500 nm, resulting in a spectral resolution of 10 nm. After the channels 1--4, 76, 87, 101--111, 136--153 and 198--210 are removed (due to dense water vapor and atmospheric effects), there remain 162  channels (this is a common preprocess for hyperspectral unmixing analyses). There is ground truth \cite{fyzhu2014IJPRSSSNMF,fyzhu2014TIPDgSNMF,fyzhu2014JSTSPRRLbSF}, which contains 4 channels: \#1 Asphalt, \#2 Grass, \#3 Tree and \#4 Roof.

A highly mixed area is cut from the original data set in this experiment (similar example was showed in \cite{wang2015abundance}), with the size of $200 \times 150$ pixels. %Fig. \ref{} shows the true-color image. 

In our experiment we compared \ICA{} to other two popular ICA methods --
ProDenICA and FastICA, see Fig. \ref{fig:spec_1}. Observe that \ICA{} and ProDenICA give layers which seem to contain more information then FastICA, as the last component in FastICA contains mainly noise.


%
%\begin{table*}[t]
%\caption{Classification accuracies for naive Bayes and flexible 
%Bayes on various data sets.}
%\label{tab:congru_img_1}
%\vskip 0.15in
%\begin{center}
%\begin{small}
%\begin{sc}
%\resizebox{\textwidth}{!}{
%\begin{tabular}{ c c c c c c c c c  c  c  c  c }
%\hline
%%\abovespace\belowspace
% & \ICA  & FastICA & FastICA & FastICA & Infomax & Infomax & Infomax & JADE & PearsonICA & ProDenICA \\ 
%  &  &  logcosh & exp & kurtosis & tanh & tangent & logistic &  & &  \\
%\hline
%%\abovespace
%
%\hline
%\end{tabular}
%}
%\end{sc}
%\end{small}
%\end{center}
%\vskip -0.1in
%\end{table*}

%\begin{table*}[!t]
%\centering
%\scalebox{0.7}{ 
%\begin{tabular}{ | c | c  | c c c | c c c | c | c | }
%\multicolumn{1}{c}{} & \multicolumn{1}{c}{\ICA}  & \multicolumn{3}{c}{FastICA} & \multicolumn{3}{c}{Infomax}  & \multicolumn{1}{c}{PearsonICA} & \multicolumn{1}{c}{ProDenICA}  \\ 
% &  &  logcosh & exp & kurtosis & tanh & tangent & logistic & &  \\
%\hline
%\#1 Asphalt  &\bf 0.6774 &  0.2859 & 0.2864 & -0.2595 & -0.2972 & -0.2954 &  -0.2972 &  0.20978 & 0.4928  \\
%\#2 Grass  & \bf -0.7784 &  -0.2746 & -0.2605 &  -0.2798 &  -0.2814 & -0.2816 & -0.2814 &  -0.2412 & -0.4323  \\
%\#3 Tree  & \bf 0.7267 & 0.2338 &  0.2717 &  -0.2547 &  0.2441 & 0.2354 &  0.2442 &   0.2482 & -0.5961  \\
%\#4 Roof &\bf 0.6666 &  -0.4256 &  0.4279 &  0.4167 & -0.4244 &  0.4301 & -0.4244 &  0.4193 &  -0.6128  \\
%
%\end{tabular}
%}
%\caption{The Tucker's congruence coefficient measure between reference layers and results of different ICA algorithms in the case of the urban data set.}
%\label{tab:spec}
%\end{table*}


%\begin{figure*}[!t]
%\normalsize
%\begin{center}
%\includegraphics[width=5in]{spec_1}
%\end{center}
%\caption{Congruence distance between layers obtain by different ICA algorithms and the closest reference channel.}
%\label{fig:spec_1}
%\end{figure*}




