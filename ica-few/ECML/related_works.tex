%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Related works}
\label{related_works}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

In literature exist a few \textbf{jesli masz na mysli malo, to few. a few to duzo} approaches dedicated for non-square ICA problem.
Most of such method are dedicated for \textbf{to zamiast for} individual methods \textbf{dwa razy method w tym zdaniu, nie wiadomo o co chodzi}.
Attias and Schreiner \cite{attias1997blind} derived a likelihood based algorithm for separation of general sequences with a frequency domain implementation.
Belouchrani and Cardoso \cite{belouchrani1995maximum} presented a general likelihood approach allowing
for additive noise and for non-square mixing matrices. They applied the
method to separation of sources taking discrete values\textbf{przecinek} and estimated the
mixing matrix using an Expectation-Maximization (EM) approach with both a deterministic and a stochastic formulation. In \cite{moulines1997maximum} \textbf{the} authors used the EM approach
for separation of autocorrelated sequences in presence of noise and explored
a family of flexible source signal priors based on Gaussian Mixtures. 

The assumption is that \textbf{usun is that} of square mixing is mostly unrealistic in  the case of EEG ant FMRI \textbf{przecinek} where the number of sources is less than the number of electrodes \cite{beckmann2004probabilistic,samarov2004nonparametric,shi2017investigating}. Therefore, many of \textbf{usun of} algorithms dedicated for \textbf{to zamiast for} this task use a probabilistic ICA \cite{tipping1999probabilistic}.
The noisy ICA model can be approximated using a variant of PCA+ICA \cite{beckmann2004probabilistic}, where probabilistic PCA is used to estimate the number of components and achieve dimension reduction \textbf{moze po prostu reduce dimension} \cite{tipping1999probabilistic}.
In \cite{allassonniere2012stochastic} \textbf{the} authors developed stochastic EM algorithms to estimate the noisy model \textbf{przecinek} and proposed parametric methods.

Other methods exploring non-Gaussian structure in multivariate data include non-Gaussian component analysis (NGCA) and projection pursuit \cite{blanchard2006search,kawanabe2007new}.
NGCA is a more general case of linear non-Gaussian component analysis (LNGCA) \cite{risk2015likelihood}
that allows non-linear dependence between the non-Gaussian components.

In the paper  \cite{miettinen2014deflation} \textbf{the} authors propose a novel \textbf{wiadomo ze novel, zamiast a novel po prostu an} adaptive twostage \textbf{two-stage?} deflation-based FastICA algorithm \textbf{przecinek} that allows one to use different nonlinearities for different components \textbf{przecinek} and optimizes the order in which the components are extracted.







